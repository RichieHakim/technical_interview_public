{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing tests for SGLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For most analyses packages that we write, we often have particular data in mind as the input. However, it is unlikely that every user will have the same data. Therefore, it is important to write tests that can be used to check that the package is working as expected.\n",
    "\n",
    "##### Your assignment here is to write two tests for the SGLM package: \n",
    "1. The first test should check that the function `sglm` returns an error when given an invalid input.\n",
    "2. The second test should check that the function `sglm` returns the correct output for a given input. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will provide the backbone of the tests in this notebook. You will need to fill in the details. Feel free to use any resources you like to help you write the tests (including generative AI). Just make sure to cite any resources you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os \n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "import glob\n",
    "import pytest\n",
    "import random\n",
    "\n",
    "from sglm import utils, glm_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write some functions to test data input \n",
    "def check_input(input_data, input_type):\n",
    "    if input_type == 'something':\n",
    "    pass\n",
    "    print('Success! Data format is correct.')\n",
    "\n",
    "def check_predictors(data, predictor_columns):\n",
    "    if data is None:\n",
    "        raise ValueError('data is empty!')\n",
    "\n",
    "    print('Success! All checks passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate fake data\n",
    "\n",
    "num_rows = 2000  \n",
    "timeseries_range = (-1, 1)\n",
    "\n",
    "# Create an empty DataFrame\n",
    "data = pd.DataFrame(columns=[\"SessionName\", \"TrialNumber\", \"Timestamp\", \"predictor1\", \"predictor2\", \"predictor3\", \"photometryNI\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_input(data, 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_predictors(data, ['predictor1', 'predictor2', 'predictor3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that you have your data, and have checked that it is in the correct format, try fitting the model and checking that the outputs are similar during different runs.\n",
    "Note: that the outputs will not look biologically plausible, but that is okay for now. We're just checking that the outputs are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'test'\n",
    "project_dir = r'path/to/project'\n",
    "\n",
    "utils.create_new_project(project_name, project_dir)\n",
    "project_path = os.path.join(project_dir, project_name)\n",
    "files = os.listdir(project_path)\n",
    "\n",
    "assert 'data' in files, 'data folder not found! {}'.format(files)\n",
    "assert 'results' in files, 'results folder not found! {}'.format(files)\n",
    "assert 'config.yaml' in files, 'config.yaml not found! {}'.format(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "index_col = ['SessionName', 'TrialNumber', 'Timestamp']\n",
    "df.set_index(index_col, inplace=True)\n",
    "\n",
    "print('Your dataframe has {} rows and {} columns'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(project_path, 'config.yaml')\n",
    "config = utils.load_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_shift, df_predictors_shift, shifted_params = glm_fit.shift_predictors(config, df)\n",
    "print('Your dataframe was shifted using: {}'.format(shifted_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = glm_fit.split_data(df_predictors_shift, response_shift, config)\n",
    "\n",
    "print('Training data has {} rows and {} columns'.format(X_train.shape[0], X_train.shape[1]))\n",
    "print('Testing data has {} rows and {} columns'.format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model, y_pred, score, beta, intercept, sparse_beta = glm_fit.fit_glm(config, X_train, X_test, y_train, y_test)\n",
    "print('Your model can account for {} percent of your data'.format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model again\n",
    "model2, y_pred2, score2, beta2, intercept2, sparse_beta2 = glm_fit.fit_glm(config, X_train, X_test, y_train, y_test)\n",
    "print('Your model can account for {} percent of your data'.format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to check the outputs of glm_fit.fit_glm\n",
    "def check_y_pred(y_pred, y_pred2, tolerance=1):\n",
    "        print('Success! y_pred and y_pred2 are simliar.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sabatini-glm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
